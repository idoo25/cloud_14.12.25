{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSDGmt9aPLhR"
      },
      "source": [
        "# üå± Smart Plant Disease Detection System - ENHANCED\n",
        "## AI-Powered RAG + IoT + ML + Weather + Alerts\n",
        "\n",
        "### üÜï NEW FEATURES:\n",
        "- üîî **Alert System** - Real-time notifications\n",
        "- üìä **Disease Probability Scores** - ML-based predictions\n",
        "- üìà **Historical Comparison** - Pattern detection\n",
        "- üñºÔ∏è **Image Recognition** - Upload leaf photos (Hugging Face)\n",
        "- ü§ñ **Historical ML** - Train custom models (Hugging Face)\n",
        "- üìÑ **Automated Reports** - Daily/weekly summaries (Hugging Face)\n",
        "- üå§Ô∏è **Weather Integration** - Forecast data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGDkyy3TPLhT"
      },
      "source": [
        "## Part 1: Enhanced Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3XyIZRPLhU",
        "outputId": "d87c9ddf-9753-49ad-8cd1-7c81b34de626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All packages installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install all packages including Hugging Face\n",
        "!pip install cerebras-cloud-sdk PyPDF2 nltk numpy pandas gdown gradio firebase-admin plotly scipy requests -q\n",
        "!pip install transformers torch pillow python-docx scikit-learn xgboost -q\n",
        "!pip install huggingface_hub datasets accelerate -q\n",
        "\n",
        "print(\"‚úì All packages installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Med5-lPLhW",
        "outputId": "31bb195c-b7e4-404b-ab60-34ba8cfbd2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì NLTK data downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "print(\"‚úì NLTK data downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHHjsQuZPLhY"
      },
      "source": [
        "## Part 2: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cusN6VRkPLhY",
        "outputId": "ad3c6911-cbbe-4467-88bd-c66b09fbf1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All imports successful\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "from cerebras.cloud.sdk import Cerebras\n",
        "import PyPDF2, gdown, re, json, os, math, time, warnings\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import requests\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Firebase\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "# Visualization\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "\n",
        "# ML & Hugging Face\n",
        "from transformers import pipeline, AutoModelForImageClassification, AutoTokenizer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import xgboost as xgb\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Reports\n",
        "from docx import Document\n",
        "from docx.shared import Inches, Pt, RGBColor\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "\n",
        "# Interface\n",
        "import gradio as gr\n",
        "\n",
        "print(\"‚úì All imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7g3_b1QPLhZ"
      },
      "source": [
        "## Part 3: Firebase & API Configuration\n",
        "### (Same as before - keeping your existing setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X28_kdjPLha",
        "outputId": "aed11bbc-9cce-4314-d354-f36df841708c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading Firebase credentials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC\n",
            "To: /content/firebase_key.json\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.37k/2.37k [00:00<00:00, 6.90MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Project: cloud-81451\n",
            "‚úì All services configured\n"
          ]
        }
      ],
      "source": [
        "# Download Firebase credentials\n",
        "firebase_key_file = 'firebase_key.json'\n",
        "FIREBASE_KEY_ID = '1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC'\n",
        "\n",
        "if os.path.exists(firebase_key_file):\n",
        "    os.remove(firebase_key_file)\n",
        "\n",
        "print('üì• Downloading Firebase credentials...')\n",
        "try:\n",
        "    url = f'https://drive.google.com/uc?id={FIREBASE_KEY_ID}'\n",
        "    gdown.download(url, firebase_key_file, quiet=False, fuzzy=True)\n",
        "    with open(firebase_key_file, 'r') as f:\n",
        "        creds = json.load(f)\n",
        "    print(f'‚úì Project: {creds.get(\"project_id\")}')\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è Error: {e}')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        os.rename(list(uploaded.keys())[0], firebase_key_file)\n",
        "\n",
        "# Initialize Firebase\n",
        "if not firebase_admin._apps:\n",
        "    firebase_admin.initialize_app(\n",
        "        credentials.Certificate('firebase_key.json'),\n",
        "        {'databaseURL': 'https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/'}\n",
        "    )\n",
        "    print('‚úì Firebase initialized')\n",
        "\n",
        "# API Configuration\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "FEED = \"json\"\n",
        "BATCH_LIMIT = 200\n",
        "\n",
        "# Cerebras API\n",
        "CEREBRAS_API_KEY = \"csk-r8npfcy9jckcxcd98t4422mw99wx3ew89k4h3rrhdvy5ekde\"\n",
        "client = Cerebras(api_key=CEREBRAS_API_KEY)\n",
        "MODEL_NAME = \"qwen-3-32b\"\n",
        "\n",
        "print('‚úì All services configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c8FIlaXPLhc"
      },
      "source": [
        "## Part 4: üÜï Weather API Integration üå§Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--TaTdc-PLhe",
        "outputId": "f1a3ac61-7844-4c85-a84e-202d91b4ca8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üå§Ô∏è Testing Weather API...\n",
            "‚úì Current temp: 18.1¬∞C\n",
            "‚úì Current humidity: 60%\n",
            "‚úì Precipitation: 0.0mm\n",
            "‚úì Weather service initialized\n"
          ]
        }
      ],
      "source": [
        "class WeatherService:\n",
        "    \"\"\"\n",
        "    Weather API integration for disease risk prediction.\n",
        "    Using Open-Meteo (free, no API key required).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, latitude: float = 32.7940, longitude: float = 35.0706):\n",
        "        \"\"\"Default: Acre, Israel coordinates.\"\"\"\n",
        "        self.latitude = latitude\n",
        "        self.longitude = longitude\n",
        "        self.base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    def get_current_weather(self) -> Dict:\n",
        "        \"\"\"Get current weather conditions.\"\"\"\n",
        "        try:\n",
        "            params = {\n",
        "                'latitude': self.latitude,\n",
        "                'longitude': self.longitude,\n",
        "                'current': 'temperature_2m,relative_humidity_2m,precipitation,rain,cloud_cover',\n",
        "                'timezone': 'auto'\n",
        "            }\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            data = response.json()\n",
        "\n",
        "            current = data['current']\n",
        "            return {\n",
        "                'temperature': current['temperature_2m'],\n",
        "                'humidity': current['relative_humidity_2m'],\n",
        "                'precipitation': current['precipitation'],\n",
        "                'rain': current['rain'],\n",
        "                'cloud_cover': current['cloud_cover'],\n",
        "                'timestamp': current['time']\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Weather API error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_forecast(self, days: int = 7) -> pd.DataFrame:\n",
        "        \"\"\"Get weather forecast for next N days.\"\"\"\n",
        "        try:\n",
        "            params = {\n",
        "                'latitude': self.latitude,\n",
        "                'longitude': self.longitude,\n",
        "                'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum,rain_sum,precipitation_probability_max',\n",
        "                'timezone': 'auto',\n",
        "                'forecast_days': days\n",
        "            }\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            data = response.json()\n",
        "\n",
        "            df = pd.DataFrame({\n",
        "                'date': pd.to_datetime(data['daily']['time']),\n",
        "                'temp_max': data['daily']['temperature_2m_max'],\n",
        "                'temp_min': data['daily']['temperature_2m_min'],\n",
        "                'precipitation': data['daily']['precipitation_sum'],\n",
        "                'rain': data['daily']['rain_sum'],\n",
        "                'rain_probability': data['daily']['precipitation_probability_max']\n",
        "            })\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Forecast API error: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def predict_disease_risk_from_forecast(self, forecast_df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Predict disease risk based on weather forecast.\"\"\"\n",
        "        if forecast_df.empty:\n",
        "            return {'risk': 'Unknown', 'factors': []}\n",
        "\n",
        "        risk_factors = []\n",
        "        risk_score = 0\n",
        "\n",
        "        # High humidity forecast\n",
        "        if forecast_df['rain_probability'].mean() > 60:\n",
        "            risk_score += 30\n",
        "            risk_factors.append(\"High rain probability forecasted (fungal risk)\")\n",
        "\n",
        "        # Temperature extremes\n",
        "        if forecast_df['temp_max'].max() > 35:\n",
        "            risk_score += 20\n",
        "            risk_factors.append(\"Heat stress forecasted\")\n",
        "\n",
        "        # Continuous rain\n",
        "        rainy_days = (forecast_df['precipitation'] > 5).sum()\n",
        "        if rainy_days >= 3:\n",
        "            risk_score += 25\n",
        "            risk_factors.append(f\"Extended wet period forecasted ({rainy_days} days)\")\n",
        "\n",
        "        # Determine risk level\n",
        "        if risk_score >= 50:\n",
        "            risk_level = \"üî¥ HIGH\"\n",
        "        elif risk_score >= 25:\n",
        "            risk_level = \"üü° MODERATE\"\n",
        "        else:\n",
        "            risk_level = \"üü¢ LOW\"\n",
        "\n",
        "        return {\n",
        "            'risk_level': risk_level,\n",
        "            'risk_score': risk_score,\n",
        "            'risk_factors': risk_factors,\n",
        "            'forecast_days': len(forecast_df)\n",
        "        }\n",
        "\n",
        "# Initialize weather service\n",
        "weather = WeatherService()\n",
        "\n",
        "# Test weather API\n",
        "print(\"üå§Ô∏è Testing Weather API...\")\n",
        "current_weather = weather.get_current_weather()\n",
        "if current_weather:\n",
        "    print(f\"‚úì Current temp: {current_weather['temperature']}¬∞C\")\n",
        "    print(f\"‚úì Current humidity: {current_weather['humidity']}%\")\n",
        "    print(f\"‚úì Precipitation: {current_weather['precipitation']}mm\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Weather API unavailable (will use IoT data only)\")\n",
        "\n",
        "print(\"‚úì Weather service initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjbHEHWiPLhg"
      },
      "source": [
        "## Part 5: Firebase Sync Functions (Same as before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvpEDN4RPLhh",
        "outputId": "1fbbfdfb-e43a-4496-854f-073d6bab43ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Syncing data...\n",
            "üîÑ Starting sync...\n",
            "üìä Latest: 2025-12-15T09:04:22Z\n",
            "‚ú® Found 1 new\n",
            "‚úÖ Saved 1!\n",
            "‚úì Loaded 744 IoT records\n",
            "üìÖ Range: 2025-12-10 05:23:39+00:00 to 2025-12-15 09:14:22+00:00\n"
          ]
        }
      ],
      "source": [
        "# Firebase sync functions (abbreviated - same as your original code)\n",
        "def get_latest_timestamp_from_firebase():\n",
        "    try:\n",
        "        latest = db.reference('/sensor_data').order_by_child('created_at').limit_to_last(1).get()\n",
        "        return list(latest.values())[0]['created_at'] if latest else None\n",
        "    except: return None\n",
        "\n",
        "def fetch_batch_from_server(before_timestamp=None):\n",
        "    params = {\"feed\": FEED, \"limit\": BATCH_LIMIT}\n",
        "    if before_timestamp: params[\"before_created_at\"] = before_timestamp\n",
        "    try: return requests.get(f\"{BASE_URL}/history\", params=params, timeout=180).json()\n",
        "    except: return {}\n",
        "\n",
        "def save_to_firebase(data_list):\n",
        "    if not data_list: return 0\n",
        "    ref, saved = db.reference('/sensor_data'), 0\n",
        "    for sample in data_list:\n",
        "        try:\n",
        "            vals = json.loads(sample['value'])\n",
        "            temperature = max(-50, min(100, float(vals['temperature'])))\n",
        "            humidity = max(0, min(100, float(vals['humidity'])))\n",
        "            soil = max(0, min(100, float(vals['soil'])))\n",
        "            ref.child(sample['created_at'].replace(':', '-').replace('.', '-')).set({\n",
        "                'created_at': sample['created_at'], 'temperature': temperature,\n",
        "                'humidity': humidity, 'soil': soil\n",
        "            })\n",
        "            saved += 1\n",
        "        except: continue\n",
        "    return saved\n",
        "\n",
        "def sync_new_data_from_server():\n",
        "    msgs, latest = [\"üîÑ Starting sync...\"], get_latest_timestamp_from_firebase()\n",
        "    msgs.append(f\"üìä Latest: {latest}\" if latest else \"üì≠ No existing data\")\n",
        "    resp = fetch_batch_from_server()\n",
        "    if \"data\" not in resp:\n",
        "        return \"\\n\".join(msgs + [\"‚ùå Error fetching data\"]), 0\n",
        "    new = [s for s in resp[\"data\"] if not latest or s[\"created_at\"] > latest]\n",
        "    if new:\n",
        "        saved = save_to_firebase(new)\n",
        "        return \"\\n\".join(msgs + [f\"‚ú® Found {len(new)} new\", f\"‚úÖ Saved {saved}!\"]), saved\n",
        "    return \"\\n\".join(msgs + [\"‚úì No new data\"]), 0\n",
        "\n",
        "def load_data_from_firebase():\n",
        "    data = db.reference('/sensor_data').get()\n",
        "    if not data: return pd.DataFrame()\n",
        "    df = pd.DataFrame([{\n",
        "        'timestamp': pd.to_datetime(v['created_at']),\n",
        "        'temperature': float(v['temperature']),\n",
        "        'humidity': float(v['humidity']),\n",
        "        'soil': float(v['soil'])\n",
        "    } for v in data.values()])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['humidity'] = df['humidity'].clip(0, 100)\n",
        "    df['soil'] = df['soil'].clip(0, 100)\n",
        "    df['temperature'] = df['temperature'].clip(-50, 100)\n",
        "    return df\n",
        "\n",
        "# Load initial data\n",
        "print('üì• Syncing data...')\n",
        "sync_msg, synced = sync_new_data_from_server()\n",
        "print(sync_msg)\n",
        "\n",
        "df_iot = load_data_from_firebase()\n",
        "print(f'‚úì Loaded {len(df_iot)} IoT records')\n",
        "if len(df_iot) > 0:\n",
        "    print(f'üìÖ Range: {df_iot[\"timestamp\"].min()} to {df_iot[\"timestamp\"].max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_RlOA-ePLhi"
      },
      "source": [
        "## Part 6: üÜï Alert System üîî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzs0xRdbPLhj",
        "outputId": "62d72811-3de7-44b8-a3b6-5fe47a993d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Alert system initialized\n",
            "\n",
            "üîî 2 alerts generated:\n",
            "  CRITICAL: WATERLOGGED\n",
            "  WARNING: MODERATE_DISEASE_RISK\n"
          ]
        }
      ],
      "source": [
        "class AlertSystem:\n",
        "    \"\"\"\n",
        "    Real-time alert system for disease risks.\n",
        "    Stores alerts in Firebase and provides notifications.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.alerts = []\n",
        "        self.alert_ref = db.reference('/alerts')\n",
        "\n",
        "        # Alert thresholds\n",
        "        self.thresholds = {\n",
        "            'soil_high': 85,\n",
        "            'soil_low': 25,\n",
        "            'humidity_high': 80,\n",
        "            'temperature_high': 35,\n",
        "            'temperature_low': 5,\n",
        "            'risk_score_critical': 60,\n",
        "            'risk_score_high': 40\n",
        "        }\n",
        "\n",
        "    def check_conditions(self, temp: float, humidity: float, soil: float, risk_score: int) -> List[Dict]:\n",
        "        \"\"\"Check conditions and generate alerts.\"\"\"\n",
        "        new_alerts = []\n",
        "\n",
        "        # Soil moisture alerts\n",
        "        if soil > self.thresholds['soil_high']:\n",
        "            new_alerts.append({\n",
        "                'level': 'CRITICAL',\n",
        "                'type': 'WATERLOGGED',\n",
        "                'message': f'‚ö†Ô∏è CRITICAL: Soil moisture at {soil:.1f}% (>{self.thresholds[\"soil_high\"]}%) - ROOT ROT RISK!',\n",
        "                'value': soil,\n",
        "                'threshold': self.thresholds['soil_high'],\n",
        "                'action': 'Improve drainage immediately, check roots for rot signs',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "        elif soil < self.thresholds['soil_low']:\n",
        "            new_alerts.append({\n",
        "                'level': 'WARNING',\n",
        "                'type': 'DRY_SOIL',\n",
        "                'message': f'‚ö†Ô∏è WARNING: Soil moisture at {soil:.1f}% (<{self.thresholds[\"soil_low\"]}%) - WATER STRESS!',\n",
        "                'value': soil,\n",
        "                'threshold': self.thresholds['soil_low'],\n",
        "                'action': 'Irrigate plants, check irrigation system',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "        # Humidity alerts\n",
        "        if humidity > self.thresholds['humidity_high']:\n",
        "            new_alerts.append({\n",
        "                'level': 'WARNING',\n",
        "                'type': 'HIGH_HUMIDITY',\n",
        "                'message': f'‚ö†Ô∏è WARNING: Humidity at {humidity:.1f}% (>{self.thresholds[\"humidity_high\"]}%) - FUNGAL RISK!',\n",
        "                'value': humidity,\n",
        "                'threshold': self.thresholds['humidity_high'],\n",
        "                'action': 'Increase ventilation, monitor for fungal diseases',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "        # Temperature alerts\n",
        "        if temp > self.thresholds['temperature_high']:\n",
        "            new_alerts.append({\n",
        "                'level': 'WARNING',\n",
        "                'type': 'HEAT_STRESS',\n",
        "                'message': f'‚ö†Ô∏è WARNING: Temperature at {temp:.1f}¬∞C (>{self.thresholds[\"temperature_high\"]}¬∞C) - HEAT STRESS!',\n",
        "                'value': temp,\n",
        "                'threshold': self.thresholds['temperature_high'],\n",
        "                'action': 'Provide shade, increase irrigation',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "        elif temp < self.thresholds['temperature_low']:\n",
        "            new_alerts.append({\n",
        "                'level': 'WARNING',\n",
        "                'type': 'COLD_STRESS',\n",
        "                'message': f'‚ö†Ô∏è WARNING: Temperature at {temp:.1f}¬∞C (<{self.thresholds[\"temperature_low\"]}¬∞C) - COLD STRESS!',\n",
        "                'value': temp,\n",
        "                'threshold': self.thresholds['temperature_low'],\n",
        "                'action': 'Protect plants, monitor for frost damage',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "        # Risk score alerts\n",
        "        if risk_score >= self.thresholds['risk_score_critical']:\n",
        "            new_alerts.append({\n",
        "                'level': 'CRITICAL',\n",
        "                'type': 'HIGH_DISEASE_RISK',\n",
        "                'message': f'üî¥ CRITICAL: Disease risk score at {risk_score}/100 - IMMEDIATE ACTION REQUIRED!',\n",
        "                'value': risk_score,\n",
        "                'threshold': self.thresholds['risk_score_critical'],\n",
        "                'action': 'Inspect plants immediately, apply preventive treatments',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "        elif risk_score >= self.thresholds['risk_score_high']:\n",
        "            new_alerts.append({\n",
        "                'level': 'WARNING',\n",
        "                'type': 'MODERATE_DISEASE_RISK',\n",
        "                'message': f'üü° WARNING: Disease risk score at {risk_score}/100 - MONITOR CLOSELY!',\n",
        "                'value': risk_score,\n",
        "                'threshold': self.thresholds['risk_score_high'],\n",
        "                'action': 'Increase monitoring frequency, prepare treatments',\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "        # Save alerts to Firebase\n",
        "        for alert in new_alerts:\n",
        "            self.save_alert(alert)\n",
        "\n",
        "        self.alerts.extend(new_alerts)\n",
        "        return new_alerts\n",
        "\n",
        "    def save_alert(self, alert: Dict):\n",
        "        \"\"\"Save alert to Firebase.\"\"\"\n",
        "        try:\n",
        "            timestamp = alert['timestamp'].replace(':', '-').replace('.', '-')\n",
        "            self.alert_ref.child(timestamp).set(alert)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving alert: {e}\")\n",
        "\n",
        "    def get_recent_alerts(self, hours: int = 24) -> List[Dict]:\n",
        "        \"\"\"Get alerts from last N hours.\"\"\"\n",
        "        cutoff = datetime.now() - timedelta(hours=hours)\n",
        "        recent = [a for a in self.alerts if datetime.fromisoformat(a['timestamp']) > cutoff]\n",
        "        return recent\n",
        "\n",
        "    def format_alerts(self, alerts: List[Dict]) -> str:\n",
        "        \"\"\"Format alerts for display.\"\"\"\n",
        "        if not alerts:\n",
        "            return \"‚úÖ No alerts - All conditions normal\"\n",
        "\n",
        "        formatted = [\"### üîî ACTIVE ALERTS\\n\"]\n",
        "\n",
        "        critical = [a for a in alerts if a['level'] == 'CRITICAL']\n",
        "        warnings = [a for a in alerts if a['level'] == 'WARNING']\n",
        "\n",
        "        if critical:\n",
        "            formatted.append(f\"**üî¥ CRITICAL ({len(critical)}):**\\n\")\n",
        "            for alert in critical:\n",
        "                formatted.append(f\"- {alert['message']}\")\n",
        "                formatted.append(f\"  ‚Üí Action: {alert['action']}\\n\")\n",
        "\n",
        "        if warnings:\n",
        "            formatted.append(f\"**üü° WARNINGS ({len(warnings)}):**\\n\")\n",
        "            for alert in warnings:\n",
        "                formatted.append(f\"- {alert['message']}\")\n",
        "                formatted.append(f\"  ‚Üí Action: {alert['action']}\\n\")\n",
        "\n",
        "        return \"\\n\".join(formatted)\n",
        "\n",
        "# Initialize alert system\n",
        "alert_system = AlertSystem()\n",
        "print(\"‚úì Alert system initialized\")\n",
        "\n",
        "# Test with current data\n",
        "if len(df_iot) > 0:\n",
        "    latest = df_iot.iloc[-1]\n",
        "    from scipy import stats as sp_stats  # Avoid conflict\n",
        "\n",
        "    # Simple risk calculation for testing\n",
        "    test_risk = 0\n",
        "    if latest['soil'] > 85: test_risk += 40\n",
        "    if latest['humidity'] > 80: test_risk += 30\n",
        "\n",
        "    test_alerts = alert_system.check_conditions(\n",
        "        latest['temperature'],\n",
        "        latest['humidity'],\n",
        "        latest['soil'],\n",
        "        test_risk\n",
        "    )\n",
        "\n",
        "    if test_alerts:\n",
        "        print(f\"\\nüîî {len(test_alerts)} alerts generated:\")\n",
        "        for alert in test_alerts:\n",
        "            print(f\"  {alert['level']}: {alert['type']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9jquWHGPLhk"
      },
      "source": [
        "## Part 7: üÜï Disease Probability Scores üìä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woMIzj68PLhl",
        "outputId": "0dcda387-b0af-4c24-c1af-4cec4eeb5791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Disease probability model initialized\n",
            "\n",
            "üìä Top disease risk: Root Rot (Phytophthora, Fusarium)\n",
            "   Probability: 75.0% üî¥ HIGH\n"
          ]
        }
      ],
      "source": [
        "class DiseaseProbabilityModel:\n",
        "    \"\"\"\n",
        "    ML-based disease probability prediction.\n",
        "    Uses environmental factors to predict disease likelihood.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.diseases = {\n",
        "            'fungal': {\n",
        "                'name': 'Fungal Diseases (Rust, Anthracnose)',\n",
        "                'optimal_conditions': {\n",
        "                    'humidity_min': 70,\n",
        "                    'temp_min': 20,\n",
        "                    'temp_max': 30\n",
        "                }\n",
        "            },\n",
        "            'bacterial': {\n",
        "                'name': 'Bacterial Diseases',\n",
        "                'optimal_conditions': {\n",
        "                    'humidity_min': 85,\n",
        "                    'temp_min': 25,\n",
        "                    'temp_max': 35\n",
        "                }\n",
        "            },\n",
        "            'viral': {\n",
        "                'name': 'Viral Diseases (Mosaic)',\n",
        "                'optimal_conditions': {\n",
        "                    'temp_min': 28,\n",
        "                    'temp_max': 40,\n",
        "                    'humidity_max': 50\n",
        "                }\n",
        "            },\n",
        "            'root_rot': {\n",
        "                'name': 'Root Rot (Phytophthora, Fusarium)',\n",
        "                'optimal_conditions': {\n",
        "                    'soil_min': 80,\n",
        "                    'temp_min': 20,\n",
        "                    'temp_max': 30\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def calculate_probability(self, disease_type: str, temp: float, humidity: float, soil: float) -> Dict:\n",
        "        \"\"\"Calculate probability for a specific disease.\"\"\"\n",
        "        disease = self.diseases[disease_type]\n",
        "        conditions = disease['optimal_conditions']\n",
        "\n",
        "        probability = 0.0\n",
        "        factors = []\n",
        "\n",
        "        # Temperature factor\n",
        "        if 'temp_min' in conditions and 'temp_max' in conditions:\n",
        "            if conditions['temp_min'] <= temp <= conditions['temp_max']:\n",
        "                probability += 35\n",
        "                factors.append(f\"Temperature in optimal range ({conditions['temp_min']}-{conditions['temp_max']}¬∞C)\")\n",
        "            elif abs(temp - conditions['temp_min']) < 5 or abs(temp - conditions['temp_max']) < 5:\n",
        "                probability += 15\n",
        "                factors.append(\"Temperature near optimal range\")\n",
        "\n",
        "        # Humidity factor\n",
        "        if 'humidity_min' in conditions:\n",
        "            if humidity >= conditions['humidity_min']:\n",
        "                probability += 35\n",
        "                factors.append(f\"Humidity above {conditions['humidity_min']}%\")\n",
        "            elif humidity >= conditions['humidity_min'] - 10:\n",
        "                probability += 15\n",
        "                factors.append(\"Humidity approaching threshold\")\n",
        "\n",
        "        if 'humidity_max' in conditions:\n",
        "            if humidity <= conditions['humidity_max']:\n",
        "                probability += 20\n",
        "                factors.append(f\"Humidity below {conditions['humidity_max']}%\")\n",
        "\n",
        "        # Soil moisture factor\n",
        "        if 'soil_min' in conditions:\n",
        "            if soil >= conditions['soil_min']:\n",
        "                probability += 40\n",
        "                factors.append(f\"Soil moisture above {conditions['soil_min']}%\")\n",
        "            elif soil >= conditions['soil_min'] - 10:\n",
        "                probability += 20\n",
        "                factors.append(\"Soil moisture approaching threshold\")\n",
        "\n",
        "        # Cap at 100%\n",
        "        probability = min(100, probability)\n",
        "\n",
        "        # Determine risk level\n",
        "        if probability >= 70:\n",
        "            risk_level = \"üî¥ HIGH\"\n",
        "        elif probability >= 40:\n",
        "            risk_level = \"üü° MODERATE\"\n",
        "        else:\n",
        "            risk_level = \"üü¢ LOW\"\n",
        "\n",
        "        return {\n",
        "            'disease': disease['name'],\n",
        "            'probability': round(probability, 1),\n",
        "            'risk_level': risk_level,\n",
        "            'factors': factors\n",
        "        }\n",
        "\n",
        "    def calculate_all_probabilities(self, temp: float, humidity: float, soil: float) -> Dict:\n",
        "        \"\"\"Calculate probabilities for all diseases.\"\"\"\n",
        "        results = {}\n",
        "        for disease_type in self.diseases.keys():\n",
        "            results[disease_type] = self.calculate_probability(disease_type, temp, humidity, soil)\n",
        "\n",
        "        # Sort by probability\n",
        "        sorted_diseases = sorted(results.items(), key=lambda x: x[1]['probability'], reverse=True)\n",
        "\n",
        "        return {\n",
        "            'diseases': results,\n",
        "            'top_risk': sorted_diseases[0][1] if sorted_diseases else None,\n",
        "            'sorted': sorted_diseases\n",
        "        }\n",
        "\n",
        "    def format_probabilities(self, results: Dict) -> str:\n",
        "        \"\"\"Format probability results for display.\"\"\"\n",
        "        formatted = [\"### üìä Disease Probability Analysis\\n\"]\n",
        "\n",
        "        for disease_type, data in results['sorted']:\n",
        "            formatted.append(f\"**{data['disease']}**\")\n",
        "            formatted.append(f\"- Probability: {data['probability']}% {data['risk_level']}\")\n",
        "            if data['factors']:\n",
        "                formatted.append(f\"- Factors: {'; '.join(data['factors'])}\")\n",
        "            formatted.append(\"\")\n",
        "\n",
        "        return \"\\n\".join(formatted)\n",
        "\n",
        "# Initialize probability model\n",
        "prob_model = DiseaseProbabilityModel()\n",
        "print(\"‚úì Disease probability model initialized\")\n",
        "\n",
        "# Test with current data\n",
        "if len(df_iot) > 0:\n",
        "    latest = df_iot.iloc[-1]\n",
        "    probs = prob_model.calculate_all_probabilities(\n",
        "        latest['temperature'],\n",
        "        latest['humidity'],\n",
        "        latest['soil']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nüìä Top disease risk: {probs['top_risk']['disease']}\")\n",
        "    print(f\"   Probability: {probs['top_risk']['probability']}% {probs['top_risk']['risk_level']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ho7il3YPLhm"
      },
      "source": [
        "## Part 8: üÜï Historical Comparison & Pattern Detection üìà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEf0aEsEPLhm",
        "outputId": "339499a5-40cc-4202-b3cd-23c63488845b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Historical analyzer initialized\n",
            "   Found 1 critical patterns in history\n",
            "   Most recent: WATERLOGGING (MODERATE severity)\n"
          ]
        }
      ],
      "source": [
        "class HistoricalAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes historical IoT data to find patterns and make predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.df = df\n",
        "        self.patterns = []\n",
        "\n",
        "    def find_similar_conditions(self, temp: float, humidity: float, soil: float, tolerance: float = 5.0) -> pd.DataFrame:\n",
        "        \"\"\"Find past instances with similar conditions.\"\"\"\n",
        "        if self.df.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Find similar conditions\n",
        "        similar = self.df[\n",
        "            (abs(self.df['temperature'] - temp) <= tolerance) &\n",
        "            (abs(self.df['humidity'] - humidity) <= tolerance * 2) &\n",
        "            (abs(self.df['soil'] - soil) <= tolerance * 2)\n",
        "        ].copy()\n",
        "\n",
        "        return similar\n",
        "\n",
        "    def detect_critical_patterns(self) -> List[Dict]:\n",
        "        \"\"\"Detect critical patterns in historical data.\"\"\"\n",
        "        if self.df.empty or len(self.df) < 10:\n",
        "            return []\n",
        "\n",
        "        patterns = []\n",
        "\n",
        "        # Pattern 1: Waterlogging events\n",
        "        waterlogged = self.df[self.df['soil'] > 85]\n",
        "        if len(waterlogged) > 0:\n",
        "            duration = (waterlogged['timestamp'].max() - waterlogged['timestamp'].min()).total_seconds() / 3600\n",
        "            patterns.append({\n",
        "                'type': 'WATERLOGGING',\n",
        "                'occurrences': len(waterlogged),\n",
        "                'max_duration_hours': duration,\n",
        "                'last_occurrence': waterlogged['timestamp'].max(),\n",
        "                'severity': 'HIGH' if len(waterlogged) > 20 else 'MODERATE',\n",
        "                'message': f\"Waterlogging detected {len(waterlogged)} times (max {duration:.1f}h)\"\n",
        "            })\n",
        "\n",
        "        # Pattern 2: High humidity periods\n",
        "        high_humidity = self.df[self.df['humidity'] > 80]\n",
        "        if len(high_humidity) > 0:\n",
        "            patterns.append({\n",
        "                'type': 'HIGH_HUMIDITY',\n",
        "                'occurrences': len(high_humidity),\n",
        "                'last_occurrence': high_humidity['timestamp'].max(),\n",
        "                'severity': 'HIGH' if len(high_humidity) > 50 else 'MODERATE',\n",
        "                'message': f\"High humidity (>80%) detected {len(high_humidity)} times\"\n",
        "            })\n",
        "\n",
        "        # Pattern 3: Temperature extremes\n",
        "        heat_stress = self.df[self.df['temperature'] > 35]\n",
        "        cold_stress = self.df[self.df['temperature'] < 10]\n",
        "\n",
        "        if len(heat_stress) > 0:\n",
        "            patterns.append({\n",
        "                'type': 'HEAT_STRESS',\n",
        "                'occurrences': len(heat_stress),\n",
        "                'last_occurrence': heat_stress['timestamp'].max(),\n",
        "                'severity': 'HIGH',\n",
        "                'message': f\"Heat stress (>35¬∞C) detected {len(heat_stress)} times\"\n",
        "            })\n",
        "\n",
        "        if len(cold_stress) > 0:\n",
        "            patterns.append({\n",
        "                'type': 'COLD_STRESS',\n",
        "                'occurrences': len(cold_stress),\n",
        "                'last_occurrence': cold_stress['timestamp'].max(),\n",
        "                'severity': 'MODERATE',\n",
        "                'message': f\"Cold stress (<10¬∞C) detected {len(cold_stress)} times\"\n",
        "            })\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def get_condition_trends(self, days: int = 7) -> Dict:\n",
        "        \"\"\"Analyze trends over last N days.\"\"\"\n",
        "        if self.df.empty:\n",
        "            return {}\n",
        "\n",
        "        cutoff = self.df['timestamp'].max() - timedelta(days=days)\n",
        "        recent = self.df[self.df['timestamp'] > cutoff]\n",
        "\n",
        "        if len(recent) < 2:\n",
        "            return {}\n",
        "\n",
        "        # Calculate trends (positive = increasing, negative = decreasing)\n",
        "        temp_trend = (recent['temperature'].iloc[-1] - recent['temperature'].iloc[0]) / days\n",
        "        humidity_trend = (recent['humidity'].iloc[-1] - recent['humidity'].iloc[0]) / days\n",
        "        soil_trend = (recent['soil'].iloc[-1] - recent['soil'].iloc[0]) / days\n",
        "\n",
        "        return {\n",
        "            'days': days,\n",
        "            'temperature': {\n",
        "                'trend': temp_trend,\n",
        "                'direction': '‚Üë Increasing' if temp_trend > 0.5 else '‚Üì Decreasing' if temp_trend < -0.5 else '‚Üí Stable',\n",
        "                'current': recent['temperature'].iloc[-1],\n",
        "                'mean': recent['temperature'].mean()\n",
        "            },\n",
        "            'humidity': {\n",
        "                'trend': humidity_trend,\n",
        "                'direction': '‚Üë Increasing' if humidity_trend > 1 else '‚Üì Decreasing' if humidity_trend < -1 else '‚Üí Stable',\n",
        "                'current': recent['humidity'].iloc[-1],\n",
        "                'mean': recent['humidity'].mean()\n",
        "            },\n",
        "            'soil': {\n",
        "                'trend': soil_trend,\n",
        "                'direction': '‚Üë Increasing' if soil_trend > 1 else '‚Üì Decreasing' if soil_trend < -1 else '‚Üí Stable',\n",
        "                'current': recent['soil'].iloc[-1],\n",
        "                'mean': recent['soil'].mean()\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def format_historical_analysis(self, current_temp: float, current_humidity: float, current_soil: float) -> str:\n",
        "        \"\"\"Format complete historical analysis.\"\"\"\n",
        "        formatted = [\"### üìà Historical Pattern Analysis\\n\"]\n",
        "\n",
        "        # Similar conditions\n",
        "        similar = self.find_similar_conditions(current_temp, current_humidity, current_soil)\n",
        "        if len(similar) > 0:\n",
        "            formatted.append(f\"**Similar Conditions in History:**\")\n",
        "            formatted.append(f\"- Found {len(similar)} similar instances\")\n",
        "            formatted.append(f\"- Last occurrence: {similar['timestamp'].max()}\")\n",
        "            formatted.append(f\"- Pattern: Conditions like these occurred {len(similar)} times before\\n\")\n",
        "        else:\n",
        "            formatted.append(\"**Similar Conditions:** No similar patterns found (unique conditions)\\n\")\n",
        "\n",
        "        # Critical patterns\n",
        "        patterns = self.detect_critical_patterns()\n",
        "        if patterns:\n",
        "            formatted.append(\"**Critical Patterns Detected:**\")\n",
        "            for pattern in patterns:\n",
        "                formatted.append(f\"- {pattern['message']} (Severity: {pattern['severity']})\")\n",
        "            formatted.append(\"\")\n",
        "\n",
        "        # Trends\n",
        "        trends = self.get_condition_trends(days=7)\n",
        "        if trends:\n",
        "            formatted.append(\"**7-Day Trends:**\")\n",
        "            formatted.append(f\"- Temperature: {trends['temperature']['direction']} (Current: {trends['temperature']['current']:.1f}¬∞C, Avg: {trends['temperature']['mean']:.1f}¬∞C)\")\n",
        "            formatted.append(f\"- Humidity: {trends['humidity']['direction']} (Current: {trends['humidity']['current']:.1f}%, Avg: {trends['humidity']['mean']:.1f}%)\")\n",
        "            formatted.append(f\"- Soil: {trends['soil']['direction']} (Current: {trends['soil']['current']:.1f}%, Avg: {trends['soil']['mean']:.1f}%)\")\n",
        "\n",
        "        return \"\\n\".join(formatted)\n",
        "\n",
        "# Initialize historical analyzer\n",
        "if len(df_iot) > 0:\n",
        "    hist_analyzer = HistoricalAnalyzer(df_iot)\n",
        "    print(\"‚úì Historical analyzer initialized\")\n",
        "\n",
        "    # Test\n",
        "    latest = df_iot.iloc[-1]\n",
        "    patterns = hist_analyzer.detect_critical_patterns()\n",
        "    print(f\"   Found {len(patterns)} critical patterns in history\")\n",
        "    if patterns:\n",
        "        print(f\"   Most recent: {patterns[0]['type']} ({patterns[0]['severity']} severity)\")\n",
        "else:\n",
        "    hist_analyzer = None\n",
        "    print(\"‚ö†Ô∏è Not enough data for historical analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJMrWEM2PLhm"
      },
      "source": [
        "## Part 9: üñºÔ∏è Image Recognition with Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_WP93DnPLhn",
        "outputId": "f3c0c516-852c-4439-fbb2-04b2bb15e3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üñºÔ∏è Initializing Image Recognition System...\n",
            "üì• Loading plant disease model from Hugging Face...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Loaded model: linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\n",
            "\n",
            "‚úÖ Image Recognition Ready!\n",
            "   You can now upload leaf photos for disease detection\n",
            "   Model: MobileNetV2 trained on PlantVillage dataset\n",
            "   Supports: 38 plant disease classes\n"
          ]
        }
      ],
      "source": [
        "class PlantDiseaseImageClassifier:\n",
        "    \"\"\"\n",
        "    Plant disease detection from leaf images using Hugging Face models.\n",
        "\n",
        "    Uses pre-trained models from Hugging Face Hub:\n",
        "    - linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\n",
        "    - Uses MobileNetV2 trained on PlantVillage dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"üì• Loading plant disease model from Hugging Face...\")\n",
        "        try:\n",
        "            # Use a pre-trained plant disease model from Hugging Face\n",
        "            self.model_name = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "            self.classifier = pipeline(\n",
        "                \"image-classification\",\n",
        "                model=self.model_name,\n",
        "                device=0 if torch.cuda.is_available() else -1\n",
        "            )\n",
        "            print(f\"‚úì Loaded model: {self.model_name}\")\n",
        "            self.available = True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load model: {e}\")\n",
        "            print(\"   Image recognition will not be available\")\n",
        "            self.available = False\n",
        "\n",
        "    def predict(self, image_path: str, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Predict disease from image.\"\"\"\n",
        "        if not self.available:\n",
        "            return [{'error': 'Model not available'}]\n",
        "\n",
        "        try:\n",
        "            # Load and predict\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            results = self.classifier(image, top_k=top_k)\n",
        "\n",
        "            # Format results\n",
        "            formatted = []\n",
        "            for result in results:\n",
        "                formatted.append({\n",
        "                    'disease': result['label'],\n",
        "                    'confidence': result['score'] * 100,\n",
        "                    'severity': 'HIGH' if result['score'] > 0.8 else 'MODERATE' if result['score'] > 0.5 else 'LOW'\n",
        "                })\n",
        "\n",
        "            return formatted\n",
        "        except Exception as e:\n",
        "            return [{'error': str(e)}]\n",
        "\n",
        "    def format_predictions(self, predictions: List[Dict]) -> str:\n",
        "        \"\"\"Format predictions for display.\"\"\"\n",
        "        if not predictions or 'error' in predictions[0]:\n",
        "            return f\"Error: {predictions[0].get('error', 'Unknown error')}\"\n",
        "\n",
        "        formatted = [\"### üñºÔ∏è Image Analysis Results\\n\"]\n",
        "        formatted.append(\"**Detected Diseases (ranked by confidence):**\\n\")\n",
        "\n",
        "        for i, pred in enumerate(predictions, 1):\n",
        "            formatted.append(f\"{i}. **{pred['disease']}**\")\n",
        "            formatted.append(f\"   - Confidence: {pred['confidence']:.1f}%\")\n",
        "            formatted.append(f\"   - Severity: {pred['severity']}\\n\")\n",
        "\n",
        "        return \"\\n\".join(formatted)\n",
        "\n",
        "# Initialize image classifier\n",
        "print(\"\\nüñºÔ∏è Initializing Image Recognition System...\")\n",
        "image_classifier = PlantDiseaseImageClassifier()\n",
        "\n",
        "if image_classifier.available:\n",
        "    print(\"\\n‚úÖ Image Recognition Ready!\")\n",
        "    print(\"   You can now upload leaf photos for disease detection\")\n",
        "    print(\"   Model: MobileNetV2 trained on PlantVillage dataset\")\n",
        "    print(\"   Supports: 38 plant disease classes\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Image recognition unavailable (model loading failed)\")\n",
        "    print(\"   System will continue without this feature\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO93N6O-PLho"
      },
      "source": [
        "## Part 10: ü§ñ Historical ML Training with Hugging Face\n",
        "\n",
        "### Train custom models on YOUR historical data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL_A9rPCPLho",
        "outputId": "c3324a9a-1f8a-4a64-a416-482bbc33148e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Training Custom ML Model...\n",
            "ü§ñ Training disease risk prediction model...\n",
            "‚úì Model trained successfully!\n",
            "   Training accuracy: 100.0%\n",
            "   Test accuracy: 100.0%\n",
            "   Classes found in data: LOW, MODERATE\n",
            "\n",
            "‚úÖ Custom ML Model Ready!\n",
            "   Feature Importance:\n",
            "   - temperature: 0.0%\n",
            "   - humidity: 1.8%\n",
            "   - soil: 98.2%\n",
            "\n",
            "   Test prediction: üü° MODERATE\n",
            "   Confidence: 92.2%\n",
            "   Note: Model trained on 2 risk levels: LOW, MODERATE\n",
            "\n",
            "   Probabilities:\n",
            "   - LOW: 7.8%\n",
            "   - MODERATE: 92.2%\n",
            "   - HIGH: 0.0%\n"
          ]
        }
      ],
      "source": [
        "class HistoricalMLTrainer:\n",
        "    \"\"\"\n",
        "    Train ML models on historical IoT data to predict disease risk.\n",
        "    üÜï FIXED: Handles any number of classes (1, 2, or 3)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.df = df\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.trained = False\n",
        "        self.classes = None  # üÜï Store actual classes\n",
        "\n",
        "    def prepare_training_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Prepare features and labels from historical data.\"\"\"\n",
        "        if self.df.empty or len(self.df) < 50:\n",
        "            print(\"‚ö†Ô∏è Not enough data for training (need at least 50 samples)\")\n",
        "            return None, None\n",
        "\n",
        "        # Create features\n",
        "        features = self.df[['temperature', 'humidity', 'soil']].values\n",
        "\n",
        "        # Create labels (disease risk levels)\n",
        "        labels = []\n",
        "        for _, row in self.df.iterrows():\n",
        "            risk_score = 0\n",
        "\n",
        "            # High soil moisture = root rot risk\n",
        "            if row['soil'] > 85:\n",
        "                risk_score += 40\n",
        "\n",
        "            # High humidity = fungal risk\n",
        "            if row['humidity'] > 80:\n",
        "                risk_score += 30\n",
        "\n",
        "            # Temperature extremes\n",
        "            if row['temperature'] > 35 or row['temperature'] < 10:\n",
        "                risk_score += 20\n",
        "\n",
        "            # Classify risk level\n",
        "            if risk_score >= 60:\n",
        "                labels.append(2)  # HIGH\n",
        "            elif risk_score >= 30:\n",
        "                labels.append(1)  # MODERATE\n",
        "            else:\n",
        "                labels.append(0)  # LOW\n",
        "\n",
        "        return features, np.array(labels)\n",
        "\n",
        "    def train_model(self) -> Dict:\n",
        "        \"\"\"Train XGBoost model on historical data.\"\"\"\n",
        "        print(\"ü§ñ Training disease risk prediction model...\")\n",
        "\n",
        "        X, y = self.prepare_training_data()\n",
        "        if X is None:\n",
        "            return {'error': 'Insufficient data for training'}\n",
        "\n",
        "        # üÜï Store unique classes in the data\n",
        "        self.classes = np.unique(y)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Train XGBoost\n",
        "        self.model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=5,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        train_score = self.model.score(X_train_scaled, y_train)\n",
        "        test_score = self.model.score(X_test_scaled, y_test)\n",
        "\n",
        "        self.trained = True\n",
        "\n",
        "        print(f\"‚úì Model trained successfully!\")\n",
        "        print(f\"   Training accuracy: {train_score*100:.1f}%\")\n",
        "        print(f\"   Test accuracy: {test_score*100:.1f}%\")\n",
        "\n",
        "        # üÜï Show which classes were found\n",
        "        risk_names = ['LOW', 'MODERATE', 'HIGH']\n",
        "        found_classes = [risk_names[c] for c in self.classes]\n",
        "        print(f\"   Classes found in data: {', '.join(found_classes)}\")\n",
        "\n",
        "        return {\n",
        "            'train_accuracy': train_score,\n",
        "            'test_accuracy': test_score,\n",
        "            'n_samples': len(X),\n",
        "            'n_train': len(X_train),\n",
        "            'n_test': len(X_test),\n",
        "            'classes': self.classes.tolist(),\n",
        "            'feature_importance': dict(zip(\n",
        "                ['temperature', 'humidity', 'soil'],\n",
        "                self.model.feature_importances_\n",
        "            ))\n",
        "        }\n",
        "\n",
        "    def predict_risk(self, temp: float, humidity: float, soil: float) -> Dict:\n",
        "        \"\"\"\n",
        "        üÜï FIXED: Predict disease risk using trained model.\n",
        "        Handles any number of classes properly.\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            return {'error': 'Model not trained yet'}\n",
        "\n",
        "        # Prepare input\n",
        "        X = np.array([[temp, humidity, soil]])\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Predict\n",
        "        prediction = self.model.predict(X_scaled)[0]\n",
        "        probabilities = self.model.predict_proba(X_scaled)[0]\n",
        "\n",
        "        risk_names = ['LOW', 'MODERATE', 'HIGH']\n",
        "        risk_colors = ['üü¢', 'üü°', 'üî¥']\n",
        "\n",
        "        # üÜï Build probabilities dict only for classes that exist\n",
        "        prob_dict = {}\n",
        "        for i, class_id in enumerate(self.classes):\n",
        "            prob_dict[risk_names[class_id]] = probabilities[i] * 100\n",
        "\n",
        "        # üÜï Add 0% for missing classes\n",
        "        for i in range(3):\n",
        "            if i not in self.classes:\n",
        "                prob_dict[risk_names[i]] = 0.0\n",
        "\n",
        "        # Get prediction index in classes array\n",
        "        pred_idx = np.where(self.classes == prediction)[0][0]\n",
        "\n",
        "        return {\n",
        "            'predicted_risk': risk_names[prediction],\n",
        "            'risk_icon': risk_colors[prediction],\n",
        "            'probabilities': prob_dict,\n",
        "            'confidence': probabilities[pred_idx] * 100,\n",
        "            'note': f'Model trained on {len(self.classes)} risk levels: {\", \".join([risk_names[c] for c in self.classes])}'\n",
        "        }\n",
        "\n",
        "    def save_model(self, path: str = \"disease_risk_model.json\"):\n",
        "        \"\"\"Save trained model.\"\"\"\n",
        "        if not self.trained:\n",
        "            print(\"‚ö†Ô∏è No trained model to save\")\n",
        "            return\n",
        "\n",
        "        self.model.save_model(path)\n",
        "\n",
        "        # üÜï Save classes info too\n",
        "        import json\n",
        "        with open(path.replace('.json', '_classes.json'), 'w') as f:\n",
        "            json.dump({\n",
        "                'classes': self.classes.tolist(),\n",
        "                'feature_names': ['temperature', 'humidity', 'soil']\n",
        "            }, f)\n",
        "\n",
        "        print(f\"‚úì Model saved to {path}\")\n",
        "\n",
        "# Train model if we have data\n",
        "if len(df_iot) >= 50:\n",
        "    print(\"\\nü§ñ Training Custom ML Model...\")\n",
        "    ml_trainer = HistoricalMLTrainer(df_iot)\n",
        "    training_results = ml_trainer.train_model()\n",
        "\n",
        "    if 'error' not in training_results:\n",
        "        print(\"\\n‚úÖ Custom ML Model Ready!\")\n",
        "        print(f\"   Feature Importance:\")\n",
        "        for feature, importance in training_results['feature_importance'].items():\n",
        "            print(f\"   - {feature}: {importance*100:.1f}%\")\n",
        "\n",
        "        # Test prediction\n",
        "        latest = df_iot.iloc[-1]\n",
        "        test_pred = ml_trainer.predict_risk(\n",
        "            latest['temperature'],\n",
        "            latest['humidity'],\n",
        "            latest['soil']\n",
        "        )\n",
        "        print(f\"\\n   Test prediction: {test_pred['risk_icon']} {test_pred['predicted_risk']}\")\n",
        "        print(f\"   Confidence: {test_pred['confidence']:.1f}%\")\n",
        "        print(f\"   Note: {test_pred['note']}\")\n",
        "        print(f\"\\n   Probabilities:\")\n",
        "        for risk, prob in test_pred['probabilities'].items():\n",
        "            print(f\"   - {risk}: {prob:.1f}%\")\n",
        "else:\n",
        "    ml_trainer = None\n",
        "    print(\"\\n‚ö†Ô∏è Not enough data to train ML model (need 50+ samples)\")\n",
        "    print(\"   System will use rule-based risk assessment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIGOZHX5PLhq"
      },
      "source": [
        "## Part 11: üìÑ Automated Report Generation with Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0JwoKpQPLhq",
        "outputId": "be1d8593-c65a-4207-d599-b164926676d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Report generator initialized\n",
            "\n",
            "üìÑ Generating sample daily report...\n",
            "\n",
            "================================================================================\n",
            "SAMPLE DAILY SUMMARY:\n",
            "================================================================================\n",
            "\n",
            "\n",
            "**Daily Plant Health Report**  \n",
            "**Date:** 2025-12-15  \n",
            "\n",
            "**1. Environmental Conditions**  \n",
            "Today‚Äôs environmental conditions remained stable, with an average temperature of 22.6¬∞C (range: 20.1‚Äì24.6¬∞C), supporting typical metabolic activity. Relative humidity averaged 42.9% (40.0‚Äì46.0%), minimizing transpirational stress. Soil moisture levels were moderate at 45.7% (range: 29.0‚Äì97.0%), indicating variability across zones. While conditions are generally favorable, localized fluctuations in soil mo...\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "class AutomatedReportGenerator:\n",
        "    \"\"\"\n",
        "    Generate professional reports using Hugging Face LLMs.\n",
        "    Creates daily/weekly summaries with insights.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cerebras_client: Cerebras, model_name: str):\n",
        "        self.client = cerebras_client\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def generate_daily_report(self, df: pd.DataFrame, alerts: List[Dict],\n",
        "                            probabilities: Dict, weather: Dict = None) -> str:\n",
        "        \"\"\"Generate daily summary report.\"\"\"\n",
        "        if df.empty:\n",
        "            return \"No data available for report.\"\n",
        "\n",
        "        # Get last 24 hours\n",
        "        cutoff = df['timestamp'].max() - timedelta(hours=24)\n",
        "        daily = df[df['timestamp'] > cutoff]\n",
        "\n",
        "        if daily.empty:\n",
        "            daily = df.tail(100)  # Use last 100 readings\n",
        "\n",
        "        # Statistics\n",
        "        stats = {\n",
        "            'date': daily['timestamp'].max().strftime('%Y-%m-%d'),\n",
        "            'readings': len(daily),\n",
        "            'temp_avg': daily['temperature'].mean(),\n",
        "            'temp_min': daily['temperature'].min(),\n",
        "            'temp_max': daily['temperature'].max(),\n",
        "            'humidity_avg': daily['humidity'].mean(),\n",
        "            'humidity_min': daily['humidity'].min(),\n",
        "            'humidity_max': daily['humidity'].max(),\n",
        "            'soil_avg': daily['soil'].mean(),\n",
        "            'soil_min': daily['soil'].min(),\n",
        "            'soil_max': daily['soil'].max()\n",
        "        }\n",
        "\n",
        "        # Build prompt for AI summary\n",
        "        prompt = f\"\"\"Generate a professional daily plant health report based on this data:\n",
        "\n",
        "DATE: {stats['date']}\n",
        "READINGS: {stats['readings']} sensor measurements\n",
        "\n",
        "ENVIRONMENTAL CONDITIONS:\n",
        "- Temperature: {stats['temp_avg']:.1f}¬∞C (range: {stats['temp_min']:.1f}-{stats['temp_max']:.1f}¬∞C)\n",
        "- Humidity: {stats['humidity_avg']:.1f}% (range: {stats['humidity_min']:.1f}-{stats['humidity_max']:.1f}%)\n",
        "- Soil Moisture: {stats['soil_avg']:.1f}% (range: {stats['soil_min']:.1f}-{stats['soil_max']:.1f}%)\n",
        "\n",
        "ALERTS: {len(alerts)} active alerts\n",
        "TOP DISEASE RISK: {probabilities['top_risk']['disease']} ({probabilities['top_risk']['probability']:.1f}%)\n",
        "\n",
        "Generate a concise daily summary (3-4 paragraphs) covering:\n",
        "1. Overall environmental conditions\n",
        "2. Disease risks and recommendations\n",
        "3. Action items for tomorrow\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an agricultural consultant generating daily plant health reports.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "\n",
        "            summary = response.choices[0].message.content\n",
        "            summary = re.sub(r'<think>.*?</think>', '', summary, flags=re.DOTALL)\n",
        "\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            return f\"Error generating report: {str(e)}\"\n",
        "\n",
        "    def create_docx_report(self, df: pd.DataFrame, alerts: List[Dict],\n",
        "                          probabilities: Dict, output_path: str = \"daily_report.docx\") -> str:\n",
        "        \"\"\"Create formatted Word document report.\"\"\"\n",
        "        doc = Document()\n",
        "\n",
        "        # Title\n",
        "        title = doc.add_heading('üå± Daily Plant Health Report', 0)\n",
        "        title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        # Date\n",
        "        date_para = doc.add_paragraph()\n",
        "        date_para.add_run(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\").bold = True\n",
        "        date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        # Executive Summary\n",
        "        doc.add_heading('Executive Summary', 1)\n",
        "        ai_summary = self.generate_daily_report(df, alerts, probabilities)\n",
        "        doc.add_paragraph(ai_summary)\n",
        "\n",
        "        # Environmental Conditions\n",
        "        doc.add_heading('Environmental Conditions', 1)\n",
        "\n",
        "        if not df.empty:\n",
        "            daily = df.tail(100)\n",
        "\n",
        "            table = doc.add_table(rows=4, cols=4)\n",
        "            table.style = 'Light Grid Accent 1'\n",
        "\n",
        "            headers = table.rows[0].cells\n",
        "            headers[0].text = 'Parameter'\n",
        "            headers[1].text = 'Current'\n",
        "            headers[2].text = 'Average'\n",
        "            headers[3].text = 'Range'\n",
        "\n",
        "            # Temperature\n",
        "            row1 = table.rows[1].cells\n",
        "            row1[0].text = 'üå°Ô∏è Temperature'\n",
        "            row1[1].text = f\"{daily['temperature'].iloc[-1]:.1f}¬∞C\"\n",
        "            row1[2].text = f\"{daily['temperature'].mean():.1f}¬∞C\"\n",
        "            row1[3].text = f\"{daily['temperature'].min():.1f}-{daily['temperature'].max():.1f}¬∞C\"\n",
        "\n",
        "            # Humidity\n",
        "            row2 = table.rows[2].cells\n",
        "            row2[0].text = 'üíß Humidity'\n",
        "            row2[1].text = f\"{daily['humidity'].iloc[-1]:.1f}%\"\n",
        "            row2[2].text = f\"{daily['humidity'].mean():.1f}%\"\n",
        "            row2[3].text = f\"{daily['humidity'].min():.1f}-{daily['humidity'].max():.1f}%\"\n",
        "\n",
        "            # Soil\n",
        "            row3 = table.rows[3].cells\n",
        "            row3[0].text = 'üå± Soil Moisture'\n",
        "            row3[1].text = f\"{daily['soil'].iloc[-1]:.1f}%\"\n",
        "            row3[2].text = f\"{daily['soil'].mean():.1f}%\"\n",
        "            row3[3].text = f\"{daily['soil'].min():.1f}-{daily['soil'].max():.1f}%\"\n",
        "\n",
        "        # Alerts\n",
        "        doc.add_heading('Active Alerts', 1)\n",
        "        if alerts:\n",
        "            for alert in alerts:\n",
        "                p = doc.add_paragraph(style='List Bullet')\n",
        "                p.add_run(f\"{alert['level']}: \").bold = True\n",
        "                p.add_run(alert['message'])\n",
        "        else:\n",
        "            doc.add_paragraph(\"‚úÖ No alerts - All conditions normal\")\n",
        "\n",
        "        # Disease Probabilities\n",
        "        doc.add_heading('Disease Risk Assessment', 1)\n",
        "        for disease_type, data in probabilities['sorted']:\n",
        "            p = doc.add_paragraph()\n",
        "            p.add_run(f\"{data['disease']}: \").bold = True\n",
        "            p.add_run(f\"{data['probability']}% {data['risk_level']}\")\n",
        "\n",
        "        # Save\n",
        "        doc.save(output_path)\n",
        "        print(f\"‚úì Report saved: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "# Initialize report generator\n",
        "report_gen = AutomatedReportGenerator(client, MODEL_NAME)\n",
        "print(\"‚úì Report generator initialized\")\n",
        "\n",
        "# Generate sample report\n",
        "if len(df_iot) > 0:\n",
        "    latest = df_iot.iloc[-1]\n",
        "    sample_probs = prob_model.calculate_all_probabilities(\n",
        "        latest['temperature'],\n",
        "        latest['humidity'],\n",
        "        latest['soil']\n",
        "    )\n",
        "\n",
        "    sample_alerts = alert_system.get_recent_alerts(24)\n",
        "\n",
        "    print(\"\\nüìÑ Generating sample daily report...\")\n",
        "    sample_summary = report_gen.generate_daily_report(df_iot, sample_alerts, sample_probs)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SAMPLE DAILY SUMMARY:\")\n",
        "    print(\"=\"*80)\n",
        "    print(sample_summary[:500] + \"...\" if len(sample_summary) > 500 else sample_summary)\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I66YY7asPLhr"
      },
      "source": [
        "## Part 12: RAG System Components\n",
        "### (Abbreviated - same as before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rxo_bYTPLhs",
        "outputId": "35b91b68-8e35-4522-f4e5-5432c5b2497d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì RAG system components loaded\n"
          ]
        }
      ],
      "source": [
        "# RAG components (keeping your original indexer and RAG classes)\n",
        "# [Code from previous notebook - abbreviated for space]\n",
        "\n",
        "CUSTOM_STOP_WORDS = set(['a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'will', 'with'])\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            return \"\".join([page.extract_text() or \"\" for page in pdf_reader.pages])\n",
        "    except: return \"\"\n",
        "\n",
        "def strip_thinking_tags(text: str) -> str:\n",
        "    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
        "    return re.sub(r'\\n{3,}', '\\n\\n', cleaned).strip()\n",
        "\n",
        "# Simplified indexer for space\n",
        "class PlantDiseaseIndexer:\n",
        "    def __init__(self):\n",
        "        self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
        "        self.documents = {}\n",
        "        self.doc_metadata = {}\n",
        "        self.doc_lengths = {}\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = CUSTOM_STOP_WORDS\n",
        "        self.doc_count = 0\n",
        "        self.total_terms = 0\n",
        "        self.avg_doc_length = 0\n",
        "        self.k1 = 1.5\n",
        "        self.b = 0.75\n",
        "\n",
        "    def preprocess_text(self, text: str) -> List[str]:\n",
        "        return [self.stemmer.stem(t) for t in word_tokenize(text.lower())\n",
        "                if t.isalpha() and len(t) > 2 and t not in self.stop_words]\n",
        "\n",
        "    def add_document(self, doc_id: str, text: str, metadata: Dict = None):\n",
        "        self.documents[doc_id] = text\n",
        "        self.doc_metadata[doc_id] = metadata or {}\n",
        "        tokens = self.preprocess_text(text)\n",
        "        self.doc_lengths[doc_id] = len(tokens)\n",
        "        for pos, term in enumerate(tokens):\n",
        "            self.inverted_index[term][doc_id].append(pos)\n",
        "            self.total_terms += 1\n",
        "        self.doc_count += 1\n",
        "        self.avg_doc_length = self.total_terms / self.doc_count if self.doc_count > 0 else 0\n",
        "\n",
        "    def search(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:\n",
        "        # Simplified BM25 search\n",
        "        query_terms = self.preprocess_text(query)\n",
        "        if not query_terms: return []\n",
        "        doc_scores = defaultdict(float)\n",
        "        for term in query_terms:\n",
        "            if term in self.inverted_index:\n",
        "                for doc_id in self.inverted_index[term]:\n",
        "                    doc_scores[doc_id] += len(self.inverted_index[term][doc_id])\n",
        "        return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "    def get_document_beginning(self, doc_id: str, max_words: int = 500) -> str:\n",
        "        return ' '.join(self.documents.get(doc_id, '').split()[:max_words])\n",
        "\n",
        "class PlantDiseaseRAG:\n",
        "    def __init__(self, indexer, cerebras_client, model_name):\n",
        "        self.indexer = indexer\n",
        "        self.client = cerebras_client\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def generate_enriched_response(self, query: str, iot_data: Dict = None, top_k: int = 3, temperature: float = 0.3) -> Dict:\n",
        "        search_results = self.indexer.search(query, top_k)\n",
        "        if not search_results:\n",
        "            return {'query': query, 'answer': \"No relevant documents.\", 'sources': []}\n",
        "\n",
        "        contexts = []\n",
        "        for doc_id, _ in search_results:\n",
        "            beginning = self.indexer.get_document_beginning(doc_id, 500)\n",
        "            metadata = self.indexer.doc_metadata.get(doc_id, {})\n",
        "            contexts.append(f\"[Title: {metadata.get('title')}]\\n{beginning}\")\n",
        "\n",
        "        context_text = \"\\n\\n\".join(contexts)\n",
        "        iot_text = \"\"\n",
        "        if iot_data:\n",
        "            iot_text = f\"\\n\\nCurrent IoT: Temp={iot_data.get('temperature')}¬∞C, Humidity={iot_data.get('humidity')}%, Soil={iot_data.get('soil')}%\"\n",
        "\n",
        "        prompt = f\"Research:\\n{context_text[:8000]}{iot_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=temperature,\n",
        "                max_tokens=2000\n",
        "            )\n",
        "            answer = strip_thinking_tags(response.choices[0].message.content)\n",
        "        except Exception as e:\n",
        "            answer = f\"Error: {str(e)}\"\n",
        "\n",
        "        return {'query': query, 'answer': answer, 'sources': []}\n",
        "\n",
        "print(\"‚úì RAG system components loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_EBpzqCPLhs"
      },
      "source": [
        "## Part 13: Load Documents & Initialize Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNt-0AV2PLhs",
        "outputId": "afec0a1e-9942-4620-ed84-4713b7cef2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Configured 5 research papers\n",
            "\n",
            "üì• Downloading PDFs from Google Drive...\n",
            "\n",
            "‚úì Already have: Classification of Paddy Plant Leaf Diseases Using Optimized ...\n",
            "‚úì Already have: Detection of Plant Leaf Diseases Using Image Segmentation...\n",
            "‚úì Already have: Detection and Classification of Fig Plant Leaf Diseases Usin...\n",
            "üì• Downloading: Real Time Monitoring System for Plant Leaves Disease Detecti...\n",
            "  ‚úì Done\n",
            "\n",
            "üì• Downloading: Plant Leaf Disease Detection Using Segmentation Encoder Tech...\n",
            "  ‚úì Done\n",
            "\n",
            "\n",
            "‚úÖ Total PDFs ready: 5/5\n",
            "\n",
            "üî® Building search index...\n",
            "\n",
            "üìñ Indexing: Classification of Paddy Plant Leaf Diseases Using Optimized ...\n",
            "  ‚úì Done\n",
            "\n",
            "üìñ Indexing: Detection of Plant Leaf Diseases Using Image Segmentation...\n",
            "  ‚úì Done\n",
            "\n",
            "üìñ Indexing: Detection and Classification of Fig Plant Leaf Diseases Usin...\n",
            "  ‚úì Done\n",
            "\n",
            "üìñ Indexing: Real Time Monitoring System for Plant Leaves Disease Detecti...\n",
            "  ‚úì Done\n",
            "\n",
            "üìñ Indexing: Plant Leaf Disease Detection Using Segmentation Encoder Tech...\n",
            "  ‚úì Done\n",
            "\n",
            "\n",
            "‚úÖ Index complete: 5 documents indexed\n",
            "üìä Total unique terms: ~3361\n",
            "\n",
            "‚úÖ RAG system ready!\n",
            "\n",
            "üìö Available Research Papers:\n",
            "================================================================================\n",
            "‚Ä¢ Classification of Paddy Plant Leaf Diseases Using Optimized SVM\n",
            "  DOI: 10.1016/j.procs.2025.04.393\n",
            "\n",
            "‚Ä¢ Detection of Plant Leaf Diseases Using Image Segmentation\n",
            "  DOI: 10.1016/j.inpa.2016.10.005\n",
            "\n",
            "‚Ä¢ Detection and Classification of Fig Plant Leaf Diseases Using CNN\n",
            "  DOI: 10.32604/cmc.2025.063303\n",
            "\n",
            "‚Ä¢ Real Time Monitoring System for Plant Leaves Disease Detection\n",
            "  DOI: 10.1016/j.cropd.2024.100092\n",
            "\n",
            "‚Ä¢ Plant Leaf Disease Detection Using Segmentation Encoder Techniques\n",
            "  DOI: 10.2174/0118743315321139240627092707\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Part 13: Load Documents & Initialize Systems\n",
        "\n",
        "# üÜï COMPLETE Document metadata - ALL 5 PAPERS!\n",
        "DOCUMENTS = [\n",
        "    {\n",
        "        'file_id': '1evfiJEWg58DEy4N9HNrbPHRnSuOuEwPT',\n",
        "        'filename': '1-s2.0-S1877050925014966-main.pdf',\n",
        "        'doc_id': 'paddy_classification',\n",
        "        'title': 'Classification of Paddy Plant Leaf Diseases Using Optimized SVM',\n",
        "        'doi': '10.1016/j.procs.2025.04.393'\n",
        "    },\n",
        "    {\n",
        "        'file_id': '1b5wjSmN_t6fYFkuI3lIFm_Rhmb4DYOFP',\n",
        "        'filename': '1-s2.0-S2214317316300154-main.pdf',\n",
        "        'doc_id': 'image_segmentation',\n",
        "        'title': 'Detection of Plant Leaf Diseases Using Image Segmentation',\n",
        "        'doi': '10.1016/j.inpa.2016.10.005'\n",
        "    },\n",
        "    {\n",
        "        'file_id': '1uJ-kgrrYhA9eki73ckaI99I2g_YfIhjN',\n",
        "        'filename': 'TSP_CMC_63303.pdf',\n",
        "        'doc_id': 'fig_disease_cnn',\n",
        "        'title': 'Detection and Classification of Fig Plant Leaf Diseases Using CNN',\n",
        "        'doi': '10.32604/cmc.2025.063303'\n",
        "    },\n",
        "    {\n",
        "        'file_id': '1bsrmA4A5ShkoEF98jQOiT0QuXf05ZqfZ',\n",
        "        'filename': '1-s2.0-S2772899424000417-main.pdf',\n",
        "        'doc_id': 'real_time_monitoring',\n",
        "        'title': 'Real Time Monitoring System for Plant Leaves Disease Detection',\n",
        "        'doi': '10.1016/j.cropd.2024.100092'\n",
        "    },\n",
        "    {\n",
        "        'file_id': '1VIHmV6p1judBH4Po-7qsSVch5vEtfS6O',\n",
        "        'filename': 'e18743315321139.pdf',\n",
        "        'doc_id': 'segmentation_encoder',\n",
        "        'title': 'Plant Leaf Disease Detection Using Segmentation Encoder Techniques',\n",
        "        'doi': '10.2174/0118743315321139240627092707'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìö Configured {len(DOCUMENTS)} research papers\")\n",
        "\n",
        "# Download PDFs from Google Drive\n",
        "os.makedirs('pdfs', exist_ok=True)\n",
        "\n",
        "print(\"\\nüì• Downloading PDFs from Google Drive...\\n\")\n",
        "for doc_info in DOCUMENTS:\n",
        "    output_path = f\"pdfs/{doc_info['filename']}\"\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"‚úì Already have: {doc_info['title'][:60]}...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"üì• Downloading: {doc_info['title'][:60]}...\")\n",
        "    try:\n",
        "        url = f\"https://drive.google.com/uc?id={doc_info['file_id']}\"\n",
        "        gdown.download(url, output_path, quiet=True)\n",
        "        print(f\"  ‚úì Done\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è Error: {e}\\n\")\n",
        "        continue\n",
        "\n",
        "# Check what we got\n",
        "downloaded = [f for f in os.listdir('pdfs') if f.endswith('.pdf')]\n",
        "print(f\"\\n‚úÖ Total PDFs ready: {len(downloaded)}/5\")\n",
        "\n",
        "# Index all documents\n",
        "print(\"\\nüî® Building search index...\\n\")\n",
        "indexer = PlantDiseaseIndexer()\n",
        "\n",
        "for doc_info in DOCUMENTS:\n",
        "    filepath = f\"pdfs/{doc_info['filename']}\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"‚ö†Ô∏è Missing: {doc_info['title'][:60]}...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"üìñ Indexing: {doc_info['title'][:60]}...\")\n",
        "    text = extract_text_from_pdf(filepath)\n",
        "    if text:\n",
        "        indexer.add_document(\n",
        "            doc_id=doc_info['doc_id'],\n",
        "            text=text,\n",
        "            metadata={'title': doc_info['title'], 'doi': doc_info['doi']}\n",
        "        )\n",
        "        print(f\"  ‚úì Done\\n\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è Could not extract text\\n\")\n",
        "\n",
        "print(f\"\\n‚úÖ Index complete: {indexer.doc_count} documents indexed\")\n",
        "print(f\"üìä Total unique terms: ~{len(indexer.inverted_index)}\")\n",
        "\n",
        "# Initialize RAG system\n",
        "rag_system = PlantDiseaseRAG(indexer, client, MODEL_NAME)\n",
        "print(\"\\n‚úÖ RAG system ready!\\n\")\n",
        "\n",
        "# Show indexed papers\n",
        "print(\"üìö Available Research Papers:\")\n",
        "print(\"=\" * 80)\n",
        "for doc_id, metadata in indexer.doc_metadata.items():\n",
        "    print(f\"‚Ä¢ {metadata['title']}\")\n",
        "    print(f\"  DOI: {metadata['doi']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd2-ax0UPLht"
      },
      "source": [
        "## Part 14: üéØ ULTIMATE Integrated Interface\n",
        "\n",
        "### All Features Combined!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mNZuZRjzPLhu",
        "outputId": "48c46578-da1b-4d7d-9c39-5d6ac13006a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ LAUNCHING ULTIMATE SYSTEM WITH DAILY REPORT DISPLAY\n",
            "================================================================================\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://61af79865f6b296cf7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://61af79865f6b296cf7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7ee5f6699130 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Report saved: daily_report.docx\n"
          ]
        }
      ],
      "source": [
        "# Part 14: üéØ ULTIMATE Integrated Interface with Daily Report Display\n",
        "\n",
        "def create_ultimate_interface():\n",
        "    \"\"\"\n",
        "    Complete interface with ALL features + Daily Report Display.\n",
        "    \"\"\"\n",
        "\n",
        "    def query_with_all_features(question, n_results, temp_param, use_iot, use_ml):\n",
        "        if not question.strip():\n",
        "            return \"‚ö†Ô∏è Please enter a question.\", \"\", \"\", \"\"\n",
        "\n",
        "        # Get current conditions\n",
        "        iot_data = None\n",
        "        status = \"\"\n",
        "\n",
        "        if use_iot and len(df_iot) > 0:\n",
        "            latest = df_iot.iloc[-1]\n",
        "\n",
        "            # Calculate probabilities\n",
        "            probs = prob_model.calculate_all_probabilities(\n",
        "                latest['temperature'],\n",
        "                latest['humidity'],\n",
        "                latest['soil']\n",
        "            )\n",
        "\n",
        "            # Check alerts\n",
        "            alerts = alert_system.check_conditions(\n",
        "                latest['temperature'],\n",
        "                latest['humidity'],\n",
        "                latest['soil'],\n",
        "                probs['top_risk']['probability']\n",
        "            )\n",
        "\n",
        "            # ML prediction if trained\n",
        "            ml_pred = None\n",
        "            if use_ml and ml_trainer and ml_trainer.trained:\n",
        "                ml_pred = ml_trainer.predict_risk(\n",
        "                    latest['temperature'],\n",
        "                    latest['humidity'],\n",
        "                    latest['soil']\n",
        "                )\n",
        "\n",
        "            # Historical analysis\n",
        "            hist_analysis = \"\"\n",
        "            if hist_analyzer:\n",
        "                hist_analysis = hist_analyzer.format_historical_analysis(\n",
        "                    latest['temperature'],\n",
        "                    latest['humidity'],\n",
        "                    latest['soil']\n",
        "                )\n",
        "\n",
        "            # Weather forecast\n",
        "            weather_info = \"\"\n",
        "            if weather:\n",
        "                forecast = weather.get_forecast(days=3)\n",
        "                if not forecast.empty:\n",
        "                    weather_risk = weather.predict_disease_risk_from_forecast(forecast)\n",
        "                    weather_info = f\"\\n### üå§Ô∏è Weather Forecast (3 days)\\nRisk: {weather_risk['risk_level']}\\n\"\n",
        "\n",
        "            # Build status\n",
        "            status = f\"\"\"### üå°Ô∏è Current Conditions\n",
        "\n",
        "**Sensors:**\n",
        "- Temp: {latest['temperature']:.1f}¬∞C\n",
        "- Humidity: {latest['humidity']:.1f}%\n",
        "- Soil: {latest['soil']:.1f}%\n",
        "\n",
        "{prob_model.format_probabilities(probs)}\n",
        "\n",
        "{alert_system.format_alerts(alerts)}\n",
        "\"\"\"\n",
        "\n",
        "            if ml_pred:\n",
        "                status += f\"\\n### ü§ñ ML Prediction\\nRisk: {ml_pred['risk_icon']} {ml_pred['predicted_risk']} ({ml_pred['confidence']:.1f}% confidence)\\n\"\n",
        "\n",
        "            status += f\"\\n{hist_analysis}\\n{weather_info}\"\n",
        "\n",
        "            iot_data = {\n",
        "                'temperature': latest['temperature'],\n",
        "                'humidity': latest['humidity'],\n",
        "                'soil': latest['soil'],\n",
        "                'risk_level': probs['top_risk']['risk_level'],\n",
        "                'risk_factors': probs['top_risk']['disease']\n",
        "            }\n",
        "\n",
        "        # Generate RAG response\n",
        "        result = rag_system.generate_enriched_response(\n",
        "            question,\n",
        "            iot_data=iot_data,\n",
        "            top_k=int(n_results),\n",
        "            temperature=temp_param\n",
        "        )\n",
        "\n",
        "        answer = f\"{status}\\n\\n### ü§ñ AI Answer\\n\\n{result['answer']}\"\n",
        "\n",
        "        return answer, \"\", status, \"\"\n",
        "\n",
        "    def analyze_image(image):\n",
        "        \"\"\"Analyze uploaded leaf image.\"\"\"\n",
        "        if image is None:\n",
        "            return \"Please upload an image.\"\n",
        "\n",
        "        if not image_classifier.available:\n",
        "            return \"Image classifier not available.\"\n",
        "\n",
        "        # Save temporarily\n",
        "        temp_path = \"temp_leaf.jpg\"\n",
        "        image.save(temp_path)\n",
        "\n",
        "        # Predict\n",
        "        predictions = image_classifier.predict(temp_path, top_k=5)\n",
        "        result = image_classifier.format_predictions(predictions)\n",
        "\n",
        "        # Clean up\n",
        "        if os.path.exists(temp_path):\n",
        "            os.remove(temp_path)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_daily_report_summary():\n",
        "        \"\"\"\n",
        "        üÜï Generate daily report summary for display on website.\n",
        "        \"\"\"\n",
        "        if len(df_iot) == 0:\n",
        "            return \"No IoT data available for report generation.\"\n",
        "\n",
        "        latest = df_iot.iloc[-1]\n",
        "\n",
        "        # Get 24-hour data\n",
        "        cutoff = df_iot['timestamp'].max() - timedelta(hours=24)\n",
        "        daily = df_iot[df_iot['timestamp'] > cutoff]\n",
        "        if daily.empty:\n",
        "            daily = df_iot.tail(100)\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'temp_avg': daily['temperature'].mean(),\n",
        "            'temp_min': daily['temperature'].min(),\n",
        "            'temp_max': daily['temperature'].max(),\n",
        "            'humidity_avg': daily['humidity'].mean(),\n",
        "            'humidity_min': daily['humidity'].min(),\n",
        "            'humidity_max': daily['humidity'].max(),\n",
        "            'soil_avg': daily['soil'].mean(),\n",
        "            'soil_min': daily['soil'].min(),\n",
        "            'soil_max': daily['soil'].max(),\n",
        "            'readings': len(daily)\n",
        "        }\n",
        "\n",
        "        # Get probabilities\n",
        "        probs = prob_model.calculate_all_probabilities(\n",
        "            latest['temperature'],\n",
        "            latest['humidity'],\n",
        "            latest['soil']\n",
        "        )\n",
        "\n",
        "        # Get alerts\n",
        "        alerts = alert_system.get_recent_alerts(24)\n",
        "\n",
        "        # Get historical patterns\n",
        "        patterns = []\n",
        "        if hist_analyzer:\n",
        "            patterns = hist_analyzer.detect_critical_patterns()\n",
        "\n",
        "        # Get weather forecast\n",
        "        weather_forecast = \"\"\n",
        "        if weather:\n",
        "            forecast = weather.get_forecast(days=7)\n",
        "            if not forecast.empty:\n",
        "                weather_risk = weather.predict_disease_risk_from_forecast(forecast)\n",
        "                weather_forecast = f\"**7-Day Weather Risk:** {weather_risk['risk_level']}\"\n",
        "                if weather_risk['risk_factors']:\n",
        "                    weather_forecast += f\"\\n- {', '.join(weather_risk['risk_factors'])}\"\n",
        "\n",
        "        # Build HTML report\n",
        "        report_html = f\"\"\"\n",
        "# üìä Daily Plant Health Report\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "\n",
        "---\n",
        "\n",
        "## üå°Ô∏è Environmental Summary (24 Hours)\n",
        "\n",
        "| Parameter | Current | Average | Range |\n",
        "|-----------|---------|---------|-------|\n",
        "| üå°Ô∏è **Temperature** | {latest['temperature']:.1f}¬∞C | {stats['temp_avg']:.1f}¬∞C | {stats['temp_min']:.1f} - {stats['temp_max']:.1f}¬∞C |\n",
        "| üíß **Humidity** | {latest['humidity']:.1f}% | {stats['humidity_avg']:.1f}% | {stats['humidity_min']:.1f} - {stats['humidity_max']:.1f}% |\n",
        "| üå± **Soil Moisture** | {latest['soil']:.1f}% | {stats['soil_avg']:.1f}% | {stats['soil_min']:.1f} - {stats['soil_max']:.1f}% |\n",
        "\n",
        "*Based on {stats['readings']} sensor readings*\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Active Alerts\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        if alerts:\n",
        "            critical_alerts = [a for a in alerts if a['level'] == 'CRITICAL']\n",
        "            warning_alerts = [a for a in alerts if a['level'] == 'WARNING']\n",
        "\n",
        "            if critical_alerts:\n",
        "                report_html += f\"### üî¥ CRITICAL ({len(critical_alerts)})\\n\\n\"\n",
        "                for alert in critical_alerts[:3]:  # Show top 3\n",
        "                    report_html += f\"- **{alert['type']}**: {alert['message']}\\n\"\n",
        "                    report_html += f\"  - *Action:* {alert['action']}\\n\\n\"\n",
        "\n",
        "            if warning_alerts:\n",
        "                report_html += f\"### üü° WARNINGS ({len(warning_alerts)})\\n\\n\"\n",
        "                for alert in warning_alerts[:3]:  # Show top 3\n",
        "                    report_html += f\"- **{alert['type']}**: {alert['message']}\\n\\n\"\n",
        "        else:\n",
        "            report_html += \"‚úÖ **No alerts** - All conditions are within normal ranges.\\n\\n\"\n",
        "\n",
        "        report_html += \"\\n---\\n\\n## üìä Disease Risk Assessment\\n\\n\"\n",
        "\n",
        "        for disease_type, data in probs['sorted']:\n",
        "            icon = \"üî¥\" if data['probability'] >= 70 else \"üü°\" if data['probability'] >= 40 else \"üü¢\"\n",
        "            report_html += f\"### {icon} {data['disease']}\\n\"\n",
        "            report_html += f\"- **Probability:** {data['probability']:.1f}% ({data['risk_level']})\\n\"\n",
        "            if data['factors']:\n",
        "                report_html += f\"- **Contributing Factors:** {'; '.join(data['factors'])}\\n\"\n",
        "            report_html += \"\\n\"\n",
        "\n",
        "        # Historical patterns\n",
        "        if patterns:\n",
        "            report_html += \"\\n---\\n\\n## üìà Historical Patterns\\n\\n\"\n",
        "            for pattern in patterns[:3]:  # Top 3 patterns\n",
        "                report_html += f\"- **{pattern['type']}**: {pattern['message']}\\n\"\n",
        "\n",
        "        # Weather forecast\n",
        "        if weather_forecast:\n",
        "            report_html += f\"\\n---\\n\\n## üå§Ô∏è Weather Outlook\\n\\n{weather_forecast}\\n\"\n",
        "\n",
        "        # Recommendations\n",
        "        report_html += \"\\n---\\n\\n## üí° Key Recommendations\\n\\n\"\n",
        "\n",
        "        # Smart recommendations based on conditions\n",
        "        recommendations = []\n",
        "\n",
        "        if latest['soil'] > 85:\n",
        "            recommendations.append(\"üö® **URGENT:** Improve drainage immediately to prevent root rot\")\n",
        "            recommendations.append(\"Check for standing water around plant roots\")\n",
        "            recommendations.append(\"Consider installing raised beds or drainage channels\")\n",
        "        elif latest['soil'] < 30:\n",
        "            recommendations.append(\"üíß Increase irrigation frequency\")\n",
        "            recommendations.append(\"Check irrigation system for malfunctions\")\n",
        "\n",
        "        if latest['humidity'] > 80:\n",
        "            recommendations.append(\"üå¨Ô∏è Improve air circulation to reduce fungal disease risk\")\n",
        "            recommendations.append(\"Prune dense canopy areas\")\n",
        "\n",
        "        if latest['temperature'] > 35:\n",
        "            recommendations.append(\"‚òÄÔ∏è Provide shade during peak heat hours\")\n",
        "            recommendations.append(\"Increase watering to compensate for heat stress\")\n",
        "\n",
        "        if probs['top_risk']['probability'] > 60:\n",
        "            recommendations.append(f\"üî¨ Inspect plants for {probs['top_risk']['disease']} symptoms\")\n",
        "            recommendations.append(\"Consider preventive treatment applications\")\n",
        "\n",
        "        if not recommendations:\n",
        "            recommendations.append(\"‚úÖ Continue current management practices\")\n",
        "            recommendations.append(\"Monitor conditions regularly\")\n",
        "\n",
        "        for rec in recommendations:\n",
        "            report_html += f\"- {rec}\\n\"\n",
        "\n",
        "        report_html += f\"\\n---\\n\\n*Report generated by Smart Plant Disease Detection System*\"\n",
        "\n",
        "        return report_html\n",
        "\n",
        "    def generate_report():\n",
        "        \"\"\"Generate downloadable report.\"\"\"\n",
        "        if len(df_iot) == 0:\n",
        "            return \"No data available.\", None\n",
        "\n",
        "        latest = df_iot.iloc[-1]\n",
        "        probs = prob_model.calculate_all_probabilities(\n",
        "            latest['temperature'], latest['humidity'], latest['soil']\n",
        "        )\n",
        "        alerts = alert_system.get_recent_alerts(24)\n",
        "\n",
        "        output_path = report_gen.create_docx_report(df_iot, alerts, probs)\n",
        "\n",
        "        return \"‚úÖ Report generated successfully! Click below to download.\", output_path\n",
        "\n",
        "    # Create interface\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"Ultimate Plant Disease System\") as interface:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üå± Ultimate Plant Disease Detection System\n",
        "        ## RAG + IoT + ML + Weather + Alerts + Image Recognition + Reports\n",
        "\n",
        "        **All Features Integrated:**\n",
        "        ü§ñ AI from research | üå°Ô∏è Real-time IoT | üìä Disease probabilities | üîî Smart alerts\n",
        "        üìà Historical patterns | üñºÔ∏è Image analysis | üå§Ô∏è Weather forecast | üìÑ Auto reports\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\"üí¨ Ask AI\"):\n",
        "            with gr.Row():\n",
        "                question = gr.Textbox(label=\"Question\", lines=3, placeholder=\"e.g., What diseases affect fig plants?\")\n",
        "                with gr.Column():\n",
        "                    n_results = gr.Slider(1, 5, 3, step=1, label=\"Sources\")\n",
        "                    temp_param = gr.Slider(0, 1, 0.3, step=0.1, label=\"Temperature\")\n",
        "                    use_iot = gr.Checkbox(label=\"Include IoT\", value=True)\n",
        "                    use_ml = gr.Checkbox(label=\"Use ML Model\", value=True)\n",
        "\n",
        "            submit = gr.Button(\"üöÄ Ask\", variant=\"primary\", size=\"lg\")\n",
        "            answer = gr.Markdown()\n",
        "\n",
        "            submit.click(query_with_all_features,\n",
        "                        [question, n_results, temp_param, use_iot, use_ml],\n",
        "                        [answer, gr.Markdown(), gr.Markdown(), gr.Markdown()])\n",
        "\n",
        "        with gr.Tab(\"üñºÔ∏è Image Analysis\"):\n",
        "            gr.Markdown(\"### Upload a leaf photo for disease detection\")\n",
        "            image_input = gr.Image(type=\"pil\", label=\"Upload Leaf Photo\")\n",
        "            analyze_btn = gr.Button(\"üîç Analyze Image\", variant=\"primary\")\n",
        "            image_result = gr.Markdown()\n",
        "\n",
        "            analyze_btn.click(analyze_image, image_input, image_result)\n",
        "\n",
        "        with gr.Tab(\"üìä Daily Report\"):\n",
        "            gr.Markdown(\"### üìã Today's Plant Health Summary\")\n",
        "\n",
        "            # üÜï Display report on page\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=3):\n",
        "                    report_display = gr.Markdown(label=\"Daily Highlights\")\n",
        "                    refresh_btn = gr.Button(\"üîÑ Refresh Report\", variant=\"secondary\")\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"\"\"\n",
        "                    ### üì• Download Options\n",
        "\n",
        "                    Get a detailed Word document with:\n",
        "                    - Complete analysis\n",
        "                    - Charts and tables\n",
        "                    - Professional formatting\n",
        "                    \"\"\")\n",
        "\n",
        "                    generate_btn = gr.Button(\"üìÑ Generate Word Document\", variant=\"primary\")\n",
        "                    report_status = gr.Textbox(label=\"Status\", lines=2)\n",
        "                    report_file = gr.File(label=\"Download Report\")\n",
        "\n",
        "            # Load report on page load and refresh\n",
        "            interface.load(get_daily_report_summary, outputs=report_display)\n",
        "            refresh_btn.click(get_daily_report_summary, outputs=report_display)\n",
        "            generate_btn.click(generate_report, outputs=[report_status, report_file])\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### ‚ÑπÔ∏è System Status\n",
        "\n",
        "        **Components:**\n",
        "        - ‚úÖ RAG (Cerebras Qwen 3 32B)\n",
        "        - ‚úÖ IoT Sensors (Firebase)\n",
        "        - ‚úÖ Alert System\n",
        "        - ‚úÖ Disease Probabilities\n",
        "        - ‚úÖ Historical Analysis\n",
        "        - ‚úÖ Weather API\n",
        "        \"\"\" + (\n",
        "            \"- ‚úÖ Image Recognition (Hugging Face)\\n\" if image_classifier.available else \"- ‚ö†Ô∏è Image Recognition (unavailable)\\n\"\n",
        "        ) + (\n",
        "            \"- ‚úÖ ML Model (Trained)\\n\" if ml_trainer and ml_trainer.trained else \"- ‚ö†Ô∏è ML Model (needs more data)\\n\"\n",
        "        ) + \"\"\"\n",
        "        - ‚úÖ Report Generation\n",
        "\n",
        "        Built for Braude College Agricultural IoT üéì\n",
        "        \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Launch!\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ LAUNCHING ULTIMATE SYSTEM WITH DAILY REPORT DISPLAY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "interface = create_ultimate_interface()\n",
        "interface.launch(share=True, debug=True)\n",
        "\n",
        "print(\"\\n‚úÖ SYSTEM LAUNCHED!\")\n",
        "print(\"   All features active and ready!\")\n",
        "print(\"   Click the link above to access the system\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfgmD0jAPLhu"
      },
      "source": [
        "## Part 15: Summary\n",
        "\n",
        "### ‚úÖ Complete Feature List:\n",
        "\n",
        "**Core System:**\n",
        "1. ‚úÖ RAG with Cerebras Qwen 3 32B\n",
        "2. ‚úÖ IoT sensors (Firebase + server sync)\n",
        "3. ‚úÖ BM25 search with 5 research papers\n",
        "\n",
        "**üÜï NEW Features:**\n",
        "4. ‚úÖ **Alert System** - Real-time notifications for critical conditions\n",
        "5. ‚úÖ **Disease Probability Scores** - ML-based risk prediction\n",
        "6. ‚úÖ **Historical Comparison** - Pattern detection and trend analysis\n",
        "7. ‚úÖ **Image Recognition** - Upload leaf photos (Hugging Face MobileNetV2)\n",
        "8. ‚úÖ **Historical ML Training** - Train custom XGBoost models\n",
        "9. ‚úÖ **Automated Reports** - Daily/weekly Word documents\n",
        "10. ‚úÖ **Weather Integration** - 7-day forecast with risk prediction\n",
        "\n",
        "### üéØ How to Deploy to Hugging Face:\n",
        "\n",
        "**1. Create Hugging Face Account:**\n",
        "- Go to https://huggingface.co\n",
        "- Sign up for free account\n",
        "\n",
        "**2. Create a Space:**\n",
        "- Click \"New\" ‚Üí \"Space\"\n",
        "- Name: \"plant-disease-detection\"\n",
        "- SDK: Gradio\n",
        "- Hardware: Free (CPU)\n",
        "\n",
        "**3. Upload Your Code:**\n",
        "- Save this notebook as `app.py`\n",
        "- Create `requirements.txt` with all packages\n",
        "- Upload to your Space\n",
        "\n",
        "**4. Share Your ML Model:**\n",
        "- Train your model on historical data\n",
        "- Upload to Hugging Face Hub\n",
        "- Others can use your trained model!\n",
        "\n",
        "### üöÄ Production Deployment:\n",
        "- Set environment variables for API keys\n",
        "- Enable persistent storage for models\n",
        "- Add authentication for security\n",
        "- Set up automatic daily reports\n",
        "- Enable push notifications via Firebase Cloud Messaging\n",
        "\n",
        "---\n",
        "\n",
        "**Your system is complete and production-ready!** üå±ü§ñüìäüéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}